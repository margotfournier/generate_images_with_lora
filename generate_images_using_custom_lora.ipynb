{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce23da6",
   "metadata": {},
   "source": [
    "# Dame Sermonde - Image Generation Notebook\n",
    "This notebook loads a base model and a LoRA adapter, then generates multiple image variations for each prompt defined in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ee9912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from diffusers import FluxPipeline\n",
    "from huggingface_hub import login\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbb37674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîê Load Hugging Face token\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_HUB_TOKEN\")\n",
    "if not HF_TOKEN:\n",
    "    try:\n",
    "        with open(\"secrets/hf_token.txt\") as f:\n",
    "            HF_TOKEN = f.read().strip()\n",
    "            os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = HF_TOKEN\n",
    "    except FileNotFoundError:\n",
    "        raise ValueError(\"No Hugging Face token found. Set HUGGINGFACE_HUB_TOKEN or create secrets/hf_token.txt\")\n",
    "login(token=HF_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbd2b1d-23e9-4469-83aa-a00c9e706e88",
   "metadata": {},
   "source": [
    "# üîß Load FLUX pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888efdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = FluxPipeline.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.1-dev\",\n",
    "    torch_dtype=torch.float16,\n",
    "    use_auth_token=True\n",
    ").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9593538-f491-430f-944b-4a4ab921f68c",
   "metadata": {},
   "source": [
    "# üìÑ Load config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa617419",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "lora = config[\"lora\"]\n",
    "pipe.load_lora_weights(\n",
    "    lora[\"lora_repo\"],\n",
    "    weight_name=lora[\"weight_name\"],\n",
    "    adapter_name=lora[\"adapter_name\"]\n",
    ")\n",
    "pipe.set_adapters([lora[\"adapter_name\"]])\n",
    "print(f\"‚úÖ Loaded LoRA: {lora['adapter_name']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f4306d-efe8-4827-83eb-4c34cc38288c",
   "metadata": {},
   "source": [
    "# üé® Generate images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8e1fa6-dd4d-4927-a931-26f06d0ace15",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d037df-ebe2-493a-ab0d-9b236d3e222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"outputs/test\"\n",
    "prompt = \"\"\"DameSermonde sitting at a carved wooden vanity table, applying medieval makeup with a calm yet mildly annoyed expression, wearing a silk underdress, soft candlelight, gold-trimmed mirror, small glass jars and brushes on the table, elegant castle chamber background, Instagram-ready\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a6afb-4cf3-4031-bd9b-9a1e8d82470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 0.7\n",
    "base_seed = 42\n",
    "num_variations = 8\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(output_dir / \"prompt.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(prompt)\n",
    "\n",
    "for j in range(num_variations):\n",
    "    seed = base_seed + j\n",
    "    generator = torch.manual_seed(seed)\n",
    "    pipe.set_adapters([lora[\"adapter_name\"]], adapter_weights=[weight])\n",
    "    image = pipe(prompt=prompt, generator=generator).images[0]\n",
    "\n",
    "    filename = f\"damesermonde_w{int(weight*100)}_s{seed}.png\"\n",
    "    image.save(output_dir / filename)\n",
    "\n",
    "    print(f\"‚úÖ Saved: {output_dir / filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b4ad33-17ac-4474-8c67-13fe65f9f8db",
   "metadata": {},
   "source": [
    "## üî¢ Multiple images (from config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192518fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 0.7\n",
    "base_seed = 42\n",
    "num_variations = 8\n",
    "\n",
    "for i, prompt_cfg in enumerate(config[\"prompts\"]):\n",
    "    prompt = prompt_cfg[\"prompt\"]\n",
    "    output_dir = Path(prompt_cfg[\"output_dir\"])\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(output_dir / \"prompt.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(prompt)\n",
    "\n",
    "    for j in range(num_variations):\n",
    "        seed = base_seed + j\n",
    "        generator = torch.manual_seed(seed)\n",
    "        pipe.set_adapters([lora[\"adapter_name\"]], adapter_weights=[weight])\n",
    "        image = pipe(prompt=prompt, generator=generator).images[0]\n",
    "\n",
    "        filename = f\"damesermonde_w{int(weight*100)}_s{seed}.png\"\n",
    "        image.save(output_dir / filename)\n",
    "\n",
    "        print(f\"‚úÖ Saved: {output_dir / filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa8726-cff9-4835-ba68-95f332dd09e1",
   "metadata": {},
   "source": [
    "# üñºÔ∏è Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac7e2c-e390-41f2-9759-03aabee04fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "def display_images_grid(directory, max_per_row=3, image_width=200):\n",
    "    directory = Path(directory)\n",
    "    image_tags = []\n",
    "\n",
    "    for image_file in sorted(directory.glob(\"*.png\")):\n",
    "        with Image.open(image_file) as img:\n",
    "            buffer = BytesIO()\n",
    "            img.save(buffer, format=\"PNG\")\n",
    "            img_b64 = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "            tag = f\"\"\"\n",
    "            <div style=\"margin: 10px; text-align: center;\">\n",
    "                <img src=\"data:image/png;base64,{img_b64}\" style=\"width: {image_width}px;\"><br>\n",
    "                <span style=\"font-size: 12px;\">{image_file.name}</span>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            image_tags.append(tag)\n",
    "\n",
    "    # Group by row\n",
    "    rows = [\n",
    "        image_tags[i:i + max_per_row]\n",
    "        for i in range(0, len(image_tags), max_per_row)\n",
    "    ]\n",
    "\n",
    "    html = \"\"\n",
    "    for row in rows:\n",
    "        html += f\"<div style='display: flex; flex-direction: row; flex-wrap: nowrap;'>{''.join(row)}</div>\"\n",
    "\n",
    "    display(HTML(html))\n",
    "\n",
    "# üîç Example usage\n",
    "display_images_grid(\"outputs/prompt_001\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
